# model with 3 classes MobileNetV2 + openCV realtime capturing

#...................................nano train_model.py....................................
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import numpy as np
from sklearn.utils.class_weight import compute_class_weight

# ==========================
# CONFIGURATION
# ==========================

IMG_SIZE = 96
BATCH_SIZE = 32
DATASET_PATH = "fer_dataset"
EPOCHS_STAGE1 = 30
EPOCHS_STAGE2 = 30

print("Loading FER dataset...")

# ==========================
# LOAD DATASET
# ==========================

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_PATH,
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    DATASET_PATH,
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)

class_names = train_ds.class_names
print("Emotion Classes:", class_names)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(AUTOTUNE)
val_ds = val_ds.prefetch(AUTOTUNE)

# ==========================
# COMPUTE CLASS WEIGHTS
# ==========================

labels = np.concatenate([y.numpy() for x, y in train_ds], axis=0)

class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(labels),
    y=labels
)

class_weights = dict(enumerate(class_weights))
print("Class Weights:", class_weights)

# ==========================
# DATA AUGMENTATION
# ==========================

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
])

# ==========================
# LOAD PRETRAINED MODEL
# ==========================

base_model = tf.keras.applications.MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights="imagenet"
)

base_model.trainable = False

# ==========================
# BUILD MODEL
# ==========================

inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = layers.Rescaling(1./255)(inputs)
x = data_augmentation(x)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(256, activation="relu")(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(len(class_names), activation="softmax")(x)

model = tf.keras.Model(inputs, outputs)

# ==========================
# CALLBACKS
# ==========================

early_stop = EarlyStopping(monitor="val_loss", patience=7, restore_best_weights=True)

reduce_lr = ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.3,
    patience=4,
    min_lr=1e-6
)

checkpoint = ModelCheckpoint(
    "best_fer_model.h5",
    monitor="val_accuracy",
    save_best_only=True,
    mode="max"
)

# ==========================
# STAGE 1 TRAINING
# ==========================

print("Stage 1: Training classifier head")

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_STAGE1,
    callbacks=[early_stop, reduce_lr, checkpoint],
    class_weight=class_weights
)

# ==========================
# STAGE 2 FINE TUNING
# ==========================

print("Stage 2: Fine tuning deeper layers")

base_model.trainable = True

# Freeze first layers, train last ~25 layers
for layer in base_model.layers[:-25]:
    layer.trainable = False

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_STAGE2,
    callbacks=[early_stop, reduce_lr, checkpoint],
    class_weight=class_weights
)

model.save("strong_fer_model.h5")

print("Strong FER model training complete.")


#..............................realtime_test.py................................
import cv2
import numpy as np
import tensorflow as tf

# ============================
# LOAD TRAINED EMOTION MODEL
# ============================

model = tf.keras.models.load_model("strong_fer_model.h5")

# Emotion order MUST match training folder order
emotion_classes = ["angry","disgust","fear","happy","sad","surprise","neutral"]

# ============================
# FACE DETECTOR
# ============================

face_cascade = cv2.CascadeClassifier(
    cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
)

cap = cv2.VideoCapture(0)

# For smoothing output
score_history = []

print("Press 'q' to exit")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)

    total_score = 0
    count = 0

    for (x,y,w,h) in faces:
        face = frame[y:y+h, x:x+w]
        face = cv2.resize(face, (96,96))
        face = face.astype("float32") / 255.0
        face = np.expand_dims(face, axis=0)

        prediction = model.predict(face, verbose=0)[0]

        # Extract probabilities
        angry = prediction[0]
        disgust = prediction[1]
        fear = prediction[2]
        happy = prediction[3]
        sad = prediction[4]
        surprise = prediction[5]
        neutral = prediction[6]

        # ============================
        # YOUR GROUPING LOGIC
        # ============================

        attentive = happy + neutral
        attentive_no_understanding = sad + fear
        disattentive = angry + disgust

        # Normalize (important for stability)
        total = attentive + attentive_no_understanding + disattentive

        if total > 0:
            attentive /= total
            attentive_no_understanding /= total
            disattentive /= total

        # ============================
        # WEIGHTED MENTAL SCORE
        # ============================

        mental_score = (
            1.0 * attentive +
            0.6 * attentive_no_understanding +
            0.2 * disattentive
        )

        mental_percentage = mental_score * 100

        total_score += mental_percentage
        count += 1

        # Draw bounding box
        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)

        cv2.putText(frame,
                    f"Mental: {mental_percentage:.1f}%",
                    (x,y-10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0,255,0),
                    2)

    # ============================
    # CLASSROOM AVERAGE SCORE
    # ============================

    if count > 0:
        class_percentage = total_score / count

        # Smooth over last 10 frames
        score_history.append(class_percentage)
        if len(score_history) > 10:
            score_history.pop(0)

        smoothed_score = sum(score_history) / len(score_history)

        cv2.putText(frame,
                    f"Class Mental Attendance: {smoothed_score:.1f}%",
                    (30,40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (0,0,255),
                    3)

    cv2.imshow("Classroom Mental Monitoring", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()






